{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE9063-Asg2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-JZlSvCE0xn"
      },
      "source": [
        "# **Car Price Model - Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNqKwJujbFl2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zgl2tK3bTKz"
      },
      "source": [
        "Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8mHTbdqMxLA",
        "outputId": "611a86f9-79c8-4533-c12f-5f19b38d1695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# ================= import data =================\n",
        "dataFile = 'audi.csv'\n",
        "data = pd.read_csv(dataFile, sep=',')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1</td>\n",
              "      <td>2017</td>\n",
              "      <td>12500</td>\n",
              "      <td>Manual</td>\n",
              "      <td>15735</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150</td>\n",
              "      <td>55.4</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A6</td>\n",
              "      <td>2016</td>\n",
              "      <td>16500</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>36203</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>20</td>\n",
              "      <td>64.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A1</td>\n",
              "      <td>2016</td>\n",
              "      <td>11000</td>\n",
              "      <td>Manual</td>\n",
              "      <td>29946</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>30</td>\n",
              "      <td>55.4</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A4</td>\n",
              "      <td>2017</td>\n",
              "      <td>16800</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>25952</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>145</td>\n",
              "      <td>67.3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3</td>\n",
              "      <td>2019</td>\n",
              "      <td>17300</td>\n",
              "      <td>Manual</td>\n",
              "      <td>1998</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>145</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10663</th>\n",
              "      <td>A3</td>\n",
              "      <td>2020</td>\n",
              "      <td>16999</td>\n",
              "      <td>Manual</td>\n",
              "      <td>4018</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>145</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10664</th>\n",
              "      <td>A3</td>\n",
              "      <td>2020</td>\n",
              "      <td>16999</td>\n",
              "      <td>Manual</td>\n",
              "      <td>1978</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10665</th>\n",
              "      <td>A3</td>\n",
              "      <td>2020</td>\n",
              "      <td>17199</td>\n",
              "      <td>Manual</td>\n",
              "      <td>609</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10666</th>\n",
              "      <td>Q3</td>\n",
              "      <td>2017</td>\n",
              "      <td>19499</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>8646</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150</td>\n",
              "      <td>47.9</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10667</th>\n",
              "      <td>Q3</td>\n",
              "      <td>2016</td>\n",
              "      <td>15999</td>\n",
              "      <td>Manual</td>\n",
              "      <td>11855</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150</td>\n",
              "      <td>47.9</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10668 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      model  year  price transmission  mileage fuelType  tax   mpg  engineSize\n",
              "0        A1  2017  12500       Manual    15735   Petrol  150  55.4         1.4\n",
              "1        A6  2016  16500    Automatic    36203   Diesel   20  64.2         2.0\n",
              "2        A1  2016  11000       Manual    29946   Petrol   30  55.4         1.4\n",
              "3        A4  2017  16800    Automatic    25952   Diesel  145  67.3         2.0\n",
              "4        A3  2019  17300       Manual     1998   Petrol  145  49.6         1.0\n",
              "...     ...   ...    ...          ...      ...      ...  ...   ...         ...\n",
              "10663    A3  2020  16999       Manual     4018   Petrol  145  49.6         1.0\n",
              "10664    A3  2020  16999       Manual     1978   Petrol  150  49.6         1.0\n",
              "10665    A3  2020  17199       Manual      609   Petrol  150  49.6         1.0\n",
              "10666    Q3  2017  19499    Automatic     8646   Petrol  150  47.9         1.4\n",
              "10667    Q3  2016  15999       Manual    11855   Petrol  150  47.9         1.4\n",
              "\n",
              "[10668 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9GN3OmZMzoF"
      },
      "source": [
        "Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWP80FY2bKZk",
        "outputId": "50a44725-3abc-42c9-8cea-b9db852b29a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "# ============= EDA ======================\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# correlation matrix\n",
        "corr_matrix = data.corr()\n",
        "print(corr_matrix['price'].sort_values(ascending=False))\n",
        "\n",
        "# heatmap\n",
        "sns.heatmap(corr_matrix, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model           0\n",
            "year            0\n",
            "price           0\n",
            "transmission    0\n",
            "mileage         0\n",
            "fuelType        0\n",
            "tax             0\n",
            "mpg             0\n",
            "engineSize      0\n",
            "dtype: int64\n",
            "price         1.000000\n",
            "year          0.592581\n",
            "engineSize    0.591262\n",
            "tax           0.356157\n",
            "mileage      -0.535357\n",
            "mpg          -0.600334\n",
            "Name: price, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5063722cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFdmQr6Na_9R"
      },
      "source": [
        "One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrSZLbQqaH8S",
        "outputId": "f18b1f87-f432-4391-fdc6-74d5e3a2a4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "# one-hot encoding for categorical attributes\n",
        "data_onehot = pd.get_dummies(data, columns=['model', 'transmission', 'fuelType'])\n",
        "data_onehot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>mileage</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "      <th>model_ A1</th>\n",
              "      <th>model_ A2</th>\n",
              "      <th>model_ A3</th>\n",
              "      <th>model_ A4</th>\n",
              "      <th>model_ A5</th>\n",
              "      <th>model_ A6</th>\n",
              "      <th>model_ A7</th>\n",
              "      <th>model_ A8</th>\n",
              "      <th>model_ Q2</th>\n",
              "      <th>model_ Q3</th>\n",
              "      <th>model_ Q5</th>\n",
              "      <th>model_ Q7</th>\n",
              "      <th>model_ Q8</th>\n",
              "      <th>model_ R8</th>\n",
              "      <th>model_ RS3</th>\n",
              "      <th>model_ RS4</th>\n",
              "      <th>model_ RS5</th>\n",
              "      <th>model_ RS6</th>\n",
              "      <th>model_ RS7</th>\n",
              "      <th>model_ S3</th>\n",
              "      <th>model_ S4</th>\n",
              "      <th>model_ S5</th>\n",
              "      <th>model_ S8</th>\n",
              "      <th>model_ SQ5</th>\n",
              "      <th>model_ SQ7</th>\n",
              "      <th>model_ TT</th>\n",
              "      <th>transmission_Automatic</th>\n",
              "      <th>transmission_Manual</th>\n",
              "      <th>transmission_Semi-Auto</th>\n",
              "      <th>fuelType_Diesel</th>\n",
              "      <th>fuelType_Hybrid</th>\n",
              "      <th>fuelType_Petrol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017</td>\n",
              "      <td>12500</td>\n",
              "      <td>15735</td>\n",
              "      <td>150</td>\n",
              "      <td>55.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016</td>\n",
              "      <td>16500</td>\n",
              "      <td>36203</td>\n",
              "      <td>20</td>\n",
              "      <td>64.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016</td>\n",
              "      <td>11000</td>\n",
              "      <td>29946</td>\n",
              "      <td>30</td>\n",
              "      <td>55.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017</td>\n",
              "      <td>16800</td>\n",
              "      <td>25952</td>\n",
              "      <td>145</td>\n",
              "      <td>67.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>17300</td>\n",
              "      <td>1998</td>\n",
              "      <td>145</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10663</th>\n",
              "      <td>2020</td>\n",
              "      <td>16999</td>\n",
              "      <td>4018</td>\n",
              "      <td>145</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10664</th>\n",
              "      <td>2020</td>\n",
              "      <td>16999</td>\n",
              "      <td>1978</td>\n",
              "      <td>150</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10665</th>\n",
              "      <td>2020</td>\n",
              "      <td>17199</td>\n",
              "      <td>609</td>\n",
              "      <td>150</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10666</th>\n",
              "      <td>2017</td>\n",
              "      <td>19499</td>\n",
              "      <td>8646</td>\n",
              "      <td>150</td>\n",
              "      <td>47.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10667</th>\n",
              "      <td>2016</td>\n",
              "      <td>15999</td>\n",
              "      <td>11855</td>\n",
              "      <td>150</td>\n",
              "      <td>47.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10668 rows Ã— 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       year  price  mileage  ...  fuelType_Diesel  fuelType_Hybrid  fuelType_Petrol\n",
              "0      2017  12500    15735  ...                0                0                1\n",
              "1      2016  16500    36203  ...                1                0                0\n",
              "2      2016  11000    29946  ...                0                0                1\n",
              "3      2017  16800    25952  ...                1                0                0\n",
              "4      2019  17300     1998  ...                0                0                1\n",
              "...     ...    ...      ...  ...              ...              ...              ...\n",
              "10663  2020  16999     4018  ...                0                0                1\n",
              "10664  2020  16999     1978  ...                0                0                1\n",
              "10665  2020  17199      609  ...                0                0                1\n",
              "10666  2017  19499     8646  ...                0                0                1\n",
              "10667  2016  15999    11855  ...                0                0                1\n",
              "\n",
              "[10668 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPg4CWKcPcVz"
      },
      "source": [
        "Correlation Matrix After One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h6jTyikPa02",
        "outputId": "4de50a99-ddee-4a88-c3a6-b6d5b93b57be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corr_matrix_onehot = data_onehot.corr()\n",
        "corr_matrix_onehot['price'].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price                     1.000000\n",
              "year                      0.592581\n",
              "engineSize                0.591262\n",
              "model_ Q7                 0.367410\n",
              "tax                       0.356157\n",
              "model_ R8                 0.327367\n",
              "transmission_Automatic    0.264294\n",
              "transmission_Semi-Auto    0.259356\n",
              "model_ Q8                 0.256350\n",
              "model_ Q5                 0.192868\n",
              "model_ RS6                0.170989\n",
              "model_ RS5                0.126436\n",
              "model_ RS4                0.125603\n",
              "model_ A8                 0.109107\n",
              "model_ SQ7                0.061673\n",
              "model_ A7                 0.054804\n",
              "model_ RS3                0.053039\n",
              "fuelType_Hybrid           0.031946\n",
              "fuelType_Diesel           0.030452\n",
              "model_ SQ5                0.028185\n",
              "model_ S4                 0.023924\n",
              "model_ S8                 0.018039\n",
              "model_ A5                 0.017438\n",
              "model_ RS7                0.008756\n",
              "model_ Q3                 0.003427\n",
              "model_ A6                -0.004719\n",
              "model_ S3                -0.008834\n",
              "model_ Q2                -0.009366\n",
              "model_ S5                -0.009903\n",
              "model_ A2                -0.016867\n",
              "model_ TT                -0.017122\n",
              "fuelType_Petrol          -0.033733\n",
              "model_ A4                -0.086946\n",
              "model_ A3                -0.220113\n",
              "model_ A1                -0.278076\n",
              "transmission_Manual      -0.483137\n",
              "mileage                  -0.535357\n",
              "mpg                      -0.600334\n",
              "Name: price, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EEvGvvaNnje"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wuE1nnNgA7",
        "outputId": "a62aa479-c161-4823-f461-649a749dbc19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# separate features and target variable\n",
        "X = data_onehot.drop(['price'], axis=1)\n",
        "Y = data_onehot[['price']]\n",
        "\n",
        "# split training:validation:test as 60%:20%:20%\n",
        "X_train_full, X_test, Y_train_full, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_full, Y_train_full, test_size=0.25, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "scalerX = StandardScaler()\n",
        "X_train_scaled = scalerX.fit_transform(X_train)\n",
        "X_valid_scaled = scalerX.transform(X_valid)\n",
        "X_test_scaled = scalerX.transform(X_test)\n",
        "\n",
        "scalerY = StandardScaler()\n",
        "Y_train_scaled = scalerY.fit_transform(Y_train)\n",
        "Y_valid_scaled = scalerY.transform(Y_valid)\n",
        "Y_test_scaled = scalerY.transform(Y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6400, 37)\n",
            "(2134, 37)\n",
            "(2134, 37)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzR4wp9MbVAx"
      },
      "source": [
        "Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HznOL5_zbRig",
        "outputId": "1aef04eb-161c-445f-bb44-c1ac03cb52b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ========================= Modeling ==============================\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=38, learning_rate=0.01, init='glorot_uniform', activation='relu'):\n",
        "    model = keras.models.Sequential()\n",
        "\n",
        "    # input layer\n",
        "    model.add(layers.Dense(38, activation=activation, kernel_initializer=init, input_shape=input_shape))\n",
        "\n",
        "    # hidden layers\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(layers.Dense(n_neurons, activation=activation, kernel_initializer=init))\n",
        "\n",
        "    # output layer\n",
        "    model.add(layers.Dense(1, kernel_initializer=init))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "\n",
        "keras_reg = KerasRegressor(build_model)\n",
        "\n",
        "\n",
        "# ==================== Hyperparameters Tuning ===================\n",
        "\n",
        "hidden_layers = [5, 6, 7, 8]\n",
        "neurons = list(range(20, 100))\n",
        "learn_rate = [0.01, 0.001, 0.002]\n",
        "init_mode = ['he_normal', 'random_normal', 'glorot_normal']\n",
        "activate = ['relu', 'elu']\n",
        "\n",
        "\n",
        "param_grid = dict(n_hidden=hidden_layers, n_neurons=neurons, learning_rate=learn_rate,\n",
        "                  init=init_mode, activation=activate)\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_grid, cv=5, random_state=42)\n",
        "rnd_search_cv.fit(X_train_scaled, Y_train_scaled, epochs=100, validation_data=(X_valid_scaled, Y_valid_scaled),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=30)])\n",
        "\n",
        "print(rnd_search_cv.best_params_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0697\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0589\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0569\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0618\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0573\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0495\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.5166 - val_loss: 0.2573\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1957 - val_loss: 0.1811\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1523\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1364\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.1200\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1030 - val_loss: 0.1178\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.1117\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.1019\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0966\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0953\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0895\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0873\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0890\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0857\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0920\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0893\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0868\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0826\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0817\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0773\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0651 - val_loss: 0.0768\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0767\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0764\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0781\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0793\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0741\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0728\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.0738\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0723\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0703\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0714\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0707\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0793\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0678\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0684\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.0760\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0797\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.0682\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0667\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0728\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.0694\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0650\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0679\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0650\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0661\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0684\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.0730\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0539 - val_loss: 0.0655\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0646\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0654\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0650\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.0633\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0644\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0647\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0698\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.0634\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0639\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0637\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0628\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0633\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.0619\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0624\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0627\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0628\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0636\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0625\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0642\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0633\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0625\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0635\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0641\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0665\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0613\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0644\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0610\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0633\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0636\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0575\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0647\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0610\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0604\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0626\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0625\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0589\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0595\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0583\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0586\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0579\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0627\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0654\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0578\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0604\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0579\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0764\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0582\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0608\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0571\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0620\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0614\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0650\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3036\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.7005 - val_loss: 0.2854\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2492 - val_loss: 0.2045\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1735 - val_loss: 0.1857\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1553 - val_loss: 0.1556\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1606\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1131 - val_loss: 0.1290\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.1217\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1209\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1125\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.1038\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.1003\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0993\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0966\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0917\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0982\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0916\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.1029\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0868\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0850\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0826\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0813\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0912\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0817\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.0787\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0793\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0787\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.0838\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.0763\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0773\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0811\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0807\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0751\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0754\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.0754\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0711\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0739\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0744\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0719\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0730\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0712\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0683\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0695\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.0723\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0701\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0677\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.0707\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0701\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0668\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0705\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0664\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0684\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0673\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0659\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0768\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.0682\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0670\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0660\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.0695\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.0690\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0652\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0652\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0647\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0633\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0680\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0663\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0636\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0649\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0634\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0642\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0643\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0655\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.0670\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.0676\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0657\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0664\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0634\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0656\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0631\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0654\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0626\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0647\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0648\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0725\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0639\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0639\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0644\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0635\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0615\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0620\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0639\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0636\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0611\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0609\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0621\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0611\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0649\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0669\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0623\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0612\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0615\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0751\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.6103 - val_loss: 0.3729\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.2036\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.1447\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1178\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.1048\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1010\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.1021\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0897\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0925\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0878\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0833\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0825\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0843\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0792\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0890\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0740\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0657 - val_loss: 0.0753\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0738\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.0699\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0716\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0678\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0694\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0724\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0690\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0704\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.0681\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0668\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0720\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0680\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0636\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0641\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0647\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0615\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0619\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0649\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0607\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0606\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0643\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0645\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0592\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0608\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0652\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0654\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0589\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0628\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0659\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0596\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0608\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0634\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0617\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0607\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0575\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0652\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0605\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0586\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0611\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0599\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0576\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0629\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0555\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0582\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0579\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0606\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0562\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0595\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0581\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0561\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0564\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0596\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0541\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0579\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0589\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0545\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0571\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0600\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0545\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0563\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0564\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0623\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0640\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0541\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0549\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0751\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0572\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0555\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0616\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0590\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0554\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0568\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0577\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0555\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0554\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0526\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0587\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0574\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0540\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0586\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0580\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0617\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0539\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0544\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "40/40 [==============================] - 0s 2ms/step - loss: nan\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9577 - val_loss: 0.1835\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1297 - val_loss: 0.1391\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.1129\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.0985\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0979\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0809\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0771\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0702\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0632\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.0647\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0688\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0621\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0642\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0661\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0599\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0597\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0715\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0567\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0623\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0641\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0555\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0669\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0577\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0564\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0523 - val_loss: 0.0550\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0508 - val_loss: 0.0591\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0566\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0590\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0621\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0763\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0641\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0579\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0578\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0579\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0545\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0700\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0538\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0531\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0631\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0521\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0571\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0601\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0546\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0560\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0583\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0586\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0565\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0543\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0580\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0643\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0550\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0529\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0523\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0580\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0532\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0550\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0581\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0581\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0591\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0564\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0556\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0523\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0556\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0502\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0577\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0553\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0532\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0521\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0615\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0592\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0535\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0649\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0605\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0543\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.0523\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0519\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0543\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0618\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0681\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0514\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0635\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0538\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0596\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0528\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0503\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0532\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0518\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.0558\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0537\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.0632\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0536\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0537\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0518\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0551\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0480\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.6581 - val_loss: 0.1466\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.1011\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.0915\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.1129\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0894\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0771\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0698\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0683\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0831\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0738\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0973\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0717\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0645\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0642\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0726\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0632\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0677\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0674\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0826\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0604\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0707\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0708\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0606\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0626\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0633\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0627\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0669\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0620\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0670\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0494 - val_loss: 0.0578\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0584\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0562\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0671\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0612\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0671\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0553\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0609\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0572\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0601\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0723\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0555\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0706\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0534\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0581\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0562\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0534\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0548\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0584\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0618\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0673\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0575\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0547\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0558\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0546\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0593\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0641\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0572\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0543\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0601\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0627\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0521\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0586\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0553\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0531\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0545\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0588\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0574\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0569\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0521\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0618\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0537\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0611\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0733\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0529\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0581\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0730\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0601\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0654\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0532\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0526\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0496\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0541\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0545\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0582\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0535\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0572\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0592\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0647\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0576\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.0612\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0518\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0528\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0565\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0515\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0602\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0549\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0521\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0507\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0613\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0513\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0631\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: nan - val_loss: nan\n",
            "40/40 [==============================] - 0s 2ms/step - loss: nan\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.1907\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1201\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0970 - val_loss: 0.0998\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.1042\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0962\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0884\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0774\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0802\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0657\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0821\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0757\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0861\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0654\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0776\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0676\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0627\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0674\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0640\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0588\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0671\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0651\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0549\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0574\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0588\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0596\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0548\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 0.0636\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0565\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0608\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0602\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0691\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0641\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0755\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0664\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0709\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0675\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0694\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0569\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0691\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0601\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0606\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0633\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0561\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0608\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0599\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0560\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0621\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0574\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0530\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0654\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0577\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0586\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0571\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0636\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0696\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0571\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0556\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0606\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0577\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0730\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0530\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0552\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0649\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0570\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0629\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0592\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0556\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0656\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0551\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0604\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0709\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0582\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0680\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0607\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0577\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0534\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0539\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0764\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0537\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0463\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.4676 - val_loss: 0.3233\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2175 - val_loss: 0.2226\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1594 - val_loss: 0.1778\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1351 - val_loss: 0.1597\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1235 - val_loss: 0.1473\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1153 - val_loss: 0.1388\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1083 - val_loss: 0.1328\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1029 - val_loss: 0.1303\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.1194\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0936 - val_loss: 0.1148\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.1118\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.1061\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.1017\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.1011\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0963\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0941\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0915\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0876\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.0862\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0840\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0840\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0807\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0809\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0771\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0805\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0762\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0777\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0759\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0800\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0747\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0744\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0737\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0724\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0735\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0730\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0689\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0698\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0710\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0668\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0690\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0669\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0698\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0663\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0687\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0681\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0682\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0655\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0679\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0653\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0689\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0665\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0664\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0656\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0659\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0701\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0634\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0630\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0655\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0643\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0629\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0642\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0630\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0640\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0627\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0628\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0615\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0610\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0611\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0623\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0652\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0636\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0655\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0614\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0611\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0603\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0634\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0606\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0626\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0600\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0608\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0622\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0590\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0589\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0617\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0622\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0602\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0583\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0587\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0586\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0593\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0593\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0611\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0619\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0601\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0612\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0585\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0605\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0624\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0590\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0593\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0790\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.4804 - val_loss: 0.3152\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2130 - val_loss: 0.2172\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1701 - val_loss: 0.1915\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1511 - val_loss: 0.1733\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1383 - val_loss: 0.1577\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1283 - val_loss: 0.1449\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1209 - val_loss: 0.1377\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1306\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1087 - val_loss: 0.1241\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1038 - val_loss: 0.1182\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0993 - val_loss: 0.1148\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1068\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.1024\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0979\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.0954\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0908\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0891\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0862\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0845\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0821\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.0795\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0777\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0769\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0747\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0720\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0731\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0694\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0705\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0673\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0663\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0675\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0673\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0679\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0647\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0653\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0636\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0619\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0647\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0649\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0645\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0620\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0618\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0604\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0630\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0630\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0643\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0599\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0603\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0593\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0581\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0598\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0648\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0595\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0598\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0617\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0582\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0580\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0593\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0576\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0567\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0581\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0564\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.0577\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0578\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0558\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0554\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0560\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0558\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0572\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0552\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0581\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0567\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0557\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0570\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0583\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0576\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0573\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0593\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0559\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0547\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0547\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0594\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0543\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0560\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0545\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0537\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0542\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0562\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0618\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0550\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0556\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0554\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0537\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0539\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0564\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0486 - val_loss: 0.0543\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0557\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0532\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0553\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0552\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0470\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.4301 - val_loss: 0.3337\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2250 - val_loss: 0.2405\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1758 - val_loss: 0.2026\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1481 - val_loss: 0.1780\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1306 - val_loss: 0.1561\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.1469\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.1339\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.1295\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0987 - val_loss: 0.1200\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1159\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.1102\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.1054\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.1020\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.1021\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0972\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0931\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0920\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0901\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0873\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0844\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0835\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0835\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0813\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0811\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0783\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0766\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0756\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0776\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0752\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0747\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0740\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0733\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0731\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0712\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0715\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0719\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0737\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0717\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0700\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0695\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0686\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0753\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0688\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0686\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0665\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0686\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0663\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0678\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0664\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0647\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0657\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0672\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0678\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0660\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0656\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0652\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0649\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0631\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0638\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0641\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0635\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0637\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0547 - val_loss: 0.0670\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0647\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0638\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0652\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0626\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0655\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0660\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0627\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0617\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0616\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0596\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0640\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0599\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0615\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0631\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0610\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0611\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0591\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0519 - val_loss: 0.0609\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0613\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0590\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0623\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0627\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0600\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0582\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0586\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0605\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0596\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0590\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0584\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0603\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0644\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0602\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0609\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0595\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0619\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0616\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0612\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0773\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.4290 - val_loss: 0.2524\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1841 - val_loss: 0.1906\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1469 - val_loss: 0.1608\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1275 - val_loss: 0.1454\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 0.1313\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1092 - val_loss: 0.1211\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1025 - val_loss: 0.1140\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.1132\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0939 - val_loss: 0.1078\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0900 - val_loss: 0.1014\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0969\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0965\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0909\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0907\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0853\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0819\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0802\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0798\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0793\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0782\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0752\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0785\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0759\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0757\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0724\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0732\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0723\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0706\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0736\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0711\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0712\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0699\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0724\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0720\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0717\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0695\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0678\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0671\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0692\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0681\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0672\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.0673\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0669\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0669\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0660\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0657\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0654\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0642\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0646\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0594 - val_loss: 0.0691\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0649\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0715\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0670\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0630\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0635\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0581 - val_loss: 0.0626\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0624\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0637\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0647\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0624\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0638\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0623\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0671\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0629\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0606\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0609\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0620\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0606\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0622\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0603\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0607\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0629\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0604\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0598\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0595\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0604\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0636\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0590\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0592\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0604\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0574\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0532 - val_loss: 0.0599\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0582\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0593\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.0602\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0595\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0571\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0587\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0569\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0562\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0588\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0592\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0570\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0604\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0571\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0623\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0575\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0564\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0547\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0565\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0712\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 0.3616\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2691 - val_loss: 0.2587\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2082 - val_loss: 0.2112\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1748 - val_loss: 0.1815\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1522 - val_loss: 0.1609\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1364 - val_loss: 0.1463\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1249 - val_loss: 0.1345\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.1262\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1084 - val_loss: 0.1180\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.1113\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0981 - val_loss: 0.1077\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.1029\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.1002\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0946\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0933\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0905\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0881\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0854\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0844\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0856\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0832\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0719 - val_loss: 0.0792\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0828\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0800\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0766\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0741\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0739\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0664 - val_loss: 0.0736\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0654 - val_loss: 0.0742\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0648 - val_loss: 0.0738\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0643 - val_loss: 0.0732\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0645 - val_loss: 0.0705\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0638 - val_loss: 0.0725\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0637 - val_loss: 0.0698\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0623 - val_loss: 0.0710\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0633 - val_loss: 0.0695\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0671\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0676\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0678\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.0666\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0686\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0683\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0643\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0655\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0652\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0700\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0665\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0648\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0673\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0669\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0576 - val_loss: 0.0625\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0638\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0656\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0616\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0641\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0643\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0652\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0627\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0609\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0639\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0626\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0609\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0650\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0637\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0629\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0612\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0617\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0614\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0606\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0610\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0643\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0606\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0620\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0599\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0608\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0530 - val_loss: 0.0575\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0650\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0595\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0580\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0580\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0624\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0619\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0639\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0615\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0576\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0575\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0566\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0594\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0557\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0596\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0613\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0500 - val_loss: 0.0557\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0572\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0579\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0588\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0598\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0589\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0578\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0560\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0583\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0550\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.6718 - val_loss: 0.3807\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.5858 - val_loss: 0.3563\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3074 - val_loss: 0.2946\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2985 - val_loss: 0.2488\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2032 - val_loss: 0.2267\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1656 - val_loss: 0.1920\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1445 - val_loss: 0.1733\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1318 - val_loss: 0.1610\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1234 - val_loss: 0.1555\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1434\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.1421\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1032 - val_loss: 0.1297\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0977 - val_loss: 0.1276\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1165\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0971 - val_loss: 0.1150\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.1109\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0955 - val_loss: 0.1096\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.1068\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.1043\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.1149\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0926 - val_loss: 0.1591\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.0987\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0959\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0960\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.1004\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0910\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0879\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0884\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0853\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0844\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0826\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0852\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0800\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0800\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0800\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0791\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0954\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0768\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0783\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0810\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0754\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0743\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0822\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0924\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0763\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0725\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0713\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0704\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0747\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0782\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0742\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0710\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.0712\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0678\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0679\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0680\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.0780\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0692\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.0704\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.0686\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0689\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0676\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0724\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0669\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0655\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0667\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0652\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0654\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0648\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0652\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0652\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0661\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0674\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0649\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0632\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0716\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0653\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0671\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0626\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0622\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0629\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0659\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0675\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0641\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0649\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0656\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0627\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0721\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0611\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0661\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0652\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0636\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0654\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0616\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0630\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0632\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0668\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0646\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0650\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0632\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0761\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.7412 - val_loss: 0.8255\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.6135 - val_loss: 0.2980\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5715 - val_loss: 0.3099\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2351 - val_loss: 0.2214\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.2082\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1710 - val_loss: 0.1727\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1433 - val_loss: 0.1650\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1284 - val_loss: 0.1405\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 0.1362\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1081 - val_loss: 0.1276\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.1155\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.1116\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0932 - val_loss: 0.1085\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0900 - val_loss: 0.1046\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.1025\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0994\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0960\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0971\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0906\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0917\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0902\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0861\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0949\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.1060\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0833\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0933\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0810\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0789\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0781\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0771\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0780\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0747\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0751\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0741\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0729\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0619 - val_loss: 0.0729\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0783\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0769\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0624 - val_loss: 0.0757\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0730\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0702\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0705\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0694\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0709\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0737\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0690\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0690\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0687\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0683\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0718\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.0675\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0539 - val_loss: 0.0699\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0687\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0678\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0655\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0659\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0683\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0520 - val_loss: 0.0659\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0523 - val_loss: 0.0649\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0655\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.0638\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0656\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0640\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.0651\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0679\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0664\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0645\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0640\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0648\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0664\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0662\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0685\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0649\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0653\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0641\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0632\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0658\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0653\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0642\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0623\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0633\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0638\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0637\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0645\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0644\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0645\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0650\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0626\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0620\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0609\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0626\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0611\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0605\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0613\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0623\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0636\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0632\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0646\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0617\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0618\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0547\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.6874 - val_loss: 0.3887\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2756 - val_loss: 0.2288\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2404 - val_loss: 0.1796\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2956 - val_loss: 0.2560\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2104 - val_loss: 0.1512\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.1231\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1007 - val_loss: 0.1145\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0934 - val_loss: 0.1050\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.1048\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.1058\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0934\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0955\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0884\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0874\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0873\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0862\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0829\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0797\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0816\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0818\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0773\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0767\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0778\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0822\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0757\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0760\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0744\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0723\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0786\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0741\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0723\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0723\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0720\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0715\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0731\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0706\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0798\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0704\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0711\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0697\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0731\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0711\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0711\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0677\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0741\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0674\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0738\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0685\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0672\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0711\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0691\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0675\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0675\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0661\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0732\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0659\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0674\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0651\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0658\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0650\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0650\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0636\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0674\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0652\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0649\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0655\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0648\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0635\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0631\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0641\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0648\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0652\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0680\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0649\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0630\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0695\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0640\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0693\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0640\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0635\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0659\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0624\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0621\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0701\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0640\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0706\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0615\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0637\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0671\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0710\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0647\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0687\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0622\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0659\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0621\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0618\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0648\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0610\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0621\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0629\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0848\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.0443 - val_loss: 0.5029\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.3864 - val_loss: 0.3368\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.5231 - val_loss: 0.3063\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2950 - val_loss: 0.2311\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2280 - val_loss: 0.2022\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1700 - val_loss: 0.1894\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1332 - val_loss: 0.1465\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.1338\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1083 - val_loss: 0.1235\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.1200\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.1123\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.1069\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.1036\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.1003\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0984\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0957\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0765 - val_loss: 0.0933\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0907\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0892\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0880\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0867\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0847\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0841\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0836\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0812\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0842\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.0797\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.0791\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0628 - val_loss: 0.0786\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0781\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0773\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0756\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.0762\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.0751\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0750\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0759\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0748\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0737\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0749\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0736\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0723\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0726\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0723\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0710\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0714\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0708\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0706\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0707\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0706\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0698\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0691\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0687\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0695\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0691\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0693\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0696\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0684\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0519 - val_loss: 0.0701\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0673\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0691\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0666\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.0675\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0674\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0669\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0663\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0673\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0660\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0668\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0655\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0662\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0673\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0679\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0665\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0650\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0649\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0647\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0653\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0644\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.0646\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0642\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0638\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0645\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0642\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0638\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0630\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0635\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0658\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0640\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0641\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0640\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0645\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0629\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0638\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0633\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0626\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0451 - val_loss: 0.0634\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0630\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0622\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0624\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0639\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0731\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.7053 - val_loss: 0.3786\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.2259\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2120 - val_loss: 0.1864\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1637 - val_loss: 0.1571\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1381 - val_loss: 0.1431\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1216 - val_loss: 0.1352\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.1201\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.1160\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.1132\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.1074\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.1000\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.1101\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0969\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0794 - val_loss: 0.0976\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.0916\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0992\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0949\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.0852\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0912\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0843\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0844\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0662 - val_loss: 0.0988\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0882\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0806\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0815\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0630 - val_loss: 0.0848\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0780\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0774\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0750\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0747\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0763\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0751\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0738\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0734\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0743\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0786\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0832\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0728\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0738\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0547 - val_loss: 0.0738\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0700\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0727\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0705\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0689\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0715\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0686\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0791\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0759\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0727\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0678\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0730\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0721\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0691\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0682\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0675\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0495 - val_loss: 0.0686\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0679\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0658\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0681\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0730\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0670\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0670\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0648\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0654\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0645\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0637\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0700\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0677\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0668\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0640\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0699\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0644\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0638\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0715\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0640\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0668\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0636\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0646\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0655\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0482 - val_loss: 0.0657\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0651\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0651\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0645\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0649\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0725\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0651\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.0637\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0622\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0628\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0615\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0624\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0625\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0637\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0629\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0620\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0642\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0648\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0619\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0616\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0619\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0533\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.7475 - val_loss: 0.5195\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.3608 - val_loss: 0.3422\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2584 - val_loss: 0.2685\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2046 - val_loss: 0.2258\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1728 - val_loss: 0.1999\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1836\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1413 - val_loss: 0.1718\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1328 - val_loss: 0.1635\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1264 - val_loss: 0.1578\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1213 - val_loss: 0.1501\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1170 - val_loss: 0.1462\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1133 - val_loss: 0.1410\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1377\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1068 - val_loss: 0.1334\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1040 - val_loss: 0.1302\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1013 - val_loss: 0.1261\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 0.1234\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.1208\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0953 - val_loss: 0.1183\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0934 - val_loss: 0.1156\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0913 - val_loss: 0.1141\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0901 - val_loss: 0.1112\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.1105\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.1079\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.1060\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.1046\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.1036\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.1023\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.1004\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0990\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.0976\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0968\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.0955\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0942\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0940\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0932\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0921\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0917\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0908\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0889\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0722 - val_loss: 0.0888\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0878\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0872\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0865\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0866\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0854\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0847\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0839\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0687 - val_loss: 0.0840\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0841\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0847\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0826\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0835\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0668 - val_loss: 0.0822\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0823\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0810\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0817\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0655 - val_loss: 0.0807\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0803\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0804\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0795\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0786\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0795\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0784\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0774\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0769\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0769\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0628 - val_loss: 0.0782\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0628 - val_loss: 0.0767\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0761\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0763\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0757\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0756\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0617 - val_loss: 0.0749\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0747\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0747\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0751\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0751\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0738\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0601 - val_loss: 0.0775\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0739\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.0731\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0729\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0725\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0723\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0727\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0722\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0715\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0723\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0709\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0710\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0706\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0720\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0709\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0715\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0716\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0716\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0701\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0707\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0704\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0949\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.4858 - val_loss: 0.3936\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2662 - val_loss: 0.2877\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.2383\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2088\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1624 - val_loss: 0.1895\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1491 - val_loss: 0.1756\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1638\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1309 - val_loss: 0.1563\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1247 - val_loss: 0.1472\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.1423\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1143 - val_loss: 0.1359\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.1307\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.1268\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1043 - val_loss: 0.1227\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.1229\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 0.1168\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0973 - val_loss: 0.1140\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0957 - val_loss: 0.1110\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0938 - val_loss: 0.1100\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.1070\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.1057\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.1029\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.1017\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0863 - val_loss: 0.1003\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0981\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0959\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.0944\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0930\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0919\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0906\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0896\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0890\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0773 - val_loss: 0.0867\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0854\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0843\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0845\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0839\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0733 - val_loss: 0.0822\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0810\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0800\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 0.0793\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0783\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0768\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0771\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0753\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0754\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.0747\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0738\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0733\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0725\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0715\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0722\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0720\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0701\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0690\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0693\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0682\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0691\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0675\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0628 - val_loss: 0.0675\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0674\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0674\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0659\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0669\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.0659\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 0.0662\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0651\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0657\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0665\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0638\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0638\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0637\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0632\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0637\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0631\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0593 - val_loss: 0.0619\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0626\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0630\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0614\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0639\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0627\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0609\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0624\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0623\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0607\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0594\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0601\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0602\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0599\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0603\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0589\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0589\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0600\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0594\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0596\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0577\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0584\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0584\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0579\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0577\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0525\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.6118 - val_loss: 0.5332\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.3819 - val_loss: 0.3759\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2729 - val_loss: 0.2814\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2087 - val_loss: 0.2192\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1741 - val_loss: 0.1892\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1570 - val_loss: 0.1759\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1662\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1389 - val_loss: 0.1607\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1331 - val_loss: 0.1541\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.1494\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1232 - val_loss: 0.1453\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.1441\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1157 - val_loss: 0.1378\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1120 - val_loss: 0.1341\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1090 - val_loss: 0.1325\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.1285\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1039 - val_loss: 0.1261\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1015 - val_loss: 0.1268\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 0.1220\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0976 - val_loss: 0.1193\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1184\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0942 - val_loss: 0.1167\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0929 - val_loss: 0.1129\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0913 - val_loss: 0.1121\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0898 - val_loss: 0.1104\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.1075\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.1054\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.1038\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.1021\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.1009\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.1008\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0982\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0967\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0950\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0786 - val_loss: 0.0938\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0924\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0935\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0899\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0903\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0899\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.0864\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0867\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0888\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.0841\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.0833\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0833\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0699 - val_loss: 0.0818\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0806\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0799\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0786\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0781\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0778\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0777\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0776\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0762\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0752\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0653 - val_loss: 0.0777\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0648 - val_loss: 0.0747\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0647 - val_loss: 0.0738\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0750\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0725\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0634 - val_loss: 0.0723\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0630 - val_loss: 0.0716\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0723\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0703\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0715\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0710\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0699\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0700\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0690\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0689\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0690\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0686\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0602 - val_loss: 0.0675\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0673\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0674\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0594 - val_loss: 0.0668\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0668\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0658\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0656\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0649\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0651\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0675\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0647\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0671\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0642\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0645\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0642\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0639\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0647\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0636\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0630\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0643\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0631\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0624\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0625\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0630\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0640\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0632\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0614\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0645\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5428 - val_loss: 0.3960\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2635 - val_loss: 0.2755\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2093 - val_loss: 0.2383\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1866 - val_loss: 0.2135\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1703 - val_loss: 0.1961\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1583 - val_loss: 0.1829\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1481 - val_loss: 0.1737\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.1615\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1325 - val_loss: 0.1547\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.1472\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1213 - val_loss: 0.1409\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1161 - val_loss: 0.1351\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1122 - val_loss: 0.1300\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1082 - val_loss: 0.1248\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1049 - val_loss: 0.1227\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.1180\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0991 - val_loss: 0.1155\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0964 - val_loss: 0.1127\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.1111\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.1065\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0898 - val_loss: 0.1052\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.1047\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.1008\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0979\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.0966\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0957\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0928\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0926\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0909\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0884\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0893\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0883\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0869\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0734 - val_loss: 0.0853\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0839\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0830\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0820\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0813\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0813\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0801\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0687 - val_loss: 0.0788\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0784\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0674 - val_loss: 0.0780\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0785\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0766\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0760\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0754\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0651 - val_loss: 0.0749\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0755\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0642 - val_loss: 0.0741\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0745\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0728\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0720\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0727\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0623 - val_loss: 0.0726\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0714\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0714\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0708\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0612 - val_loss: 0.0708\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0695\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0604 - val_loss: 0.0698\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0603 - val_loss: 0.0688\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0600 - val_loss: 0.0689\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0689\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0677\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0678\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0677\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0672\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0666\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0668\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0663\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0671\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0663\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0654\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0651\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0660\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0649\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0652\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0568 - val_loss: 0.0649\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0640\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0566 - val_loss: 0.0643\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0638\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0638\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0635\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0633\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0636\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0628\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0631\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0624\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0624\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0631\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0624\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0615\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0545 - val_loss: 0.0625\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0620\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0632\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0613\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0620\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.0618\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0607\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.0785\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5042 - val_loss: 0.3656\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2787 - val_loss: 0.2761\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2237 - val_loss: 0.2297\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.1995\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1699 - val_loss: 0.1803\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1653\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1449 - val_loss: 0.1573\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1376 - val_loss: 0.1486\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1315 - val_loss: 0.1429\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1273 - val_loss: 0.1378\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1224 - val_loss: 0.1333\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1188 - val_loss: 0.1300\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1155 - val_loss: 0.1259\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1123 - val_loss: 0.1227\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1092 - val_loss: 0.1203\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1066 - val_loss: 0.1171\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1042 - val_loss: 0.1145\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1021 - val_loss: 0.1120\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0997 - val_loss: 0.1098\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0976 - val_loss: 0.1065\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0955 - val_loss: 0.1054\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0939 - val_loss: 0.1027\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.1012\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0902 - val_loss: 0.0996\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.0982\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0958\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0942\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0919\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0920\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0895\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0879\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0794 - val_loss: 0.0875\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0858\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.0844\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0840\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0824\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0747 - val_loss: 0.0817\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0802\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0731 - val_loss: 0.0799\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0725 - val_loss: 0.0798\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0785\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0776\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.0764\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0755\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.0753\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0755\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0684 - val_loss: 0.0743\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0752\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0740\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0720\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0720\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0716\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0715\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0706\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0714\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0652 - val_loss: 0.0704\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0646 - val_loss: 0.0690\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0643 - val_loss: 0.0686\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0691\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0637 - val_loss: 0.0680\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0633 - val_loss: 0.0683\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0631 - val_loss: 0.0679\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0673\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0679\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0674\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0676\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0674\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0659\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0658\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0654\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0674\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0654\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0664\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0605 - val_loss: 0.0648\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0657\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0599 - val_loss: 0.0636\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0641\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0641\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0651\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0635\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0634\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0649\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0635\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0640\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0623\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0647\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0626\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0612\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0621\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0629\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0620\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0575 - val_loss: 0.0639\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0615\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0605\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0614\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0616\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0610\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0622\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0612\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0617\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.0614\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.0097 - val_loss: 1.1465\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1464\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1465\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1465\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1465\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1466\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0097 - val_loss: 1.1466\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1466\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1466\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1466\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1466\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1466\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1465\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1465\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 1.1465\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1466\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.1465\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0096 - val_loss: 1.1466\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.9617\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.9878 - val_loss: 1.1463\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9878 - val_loss: 1.1462\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9878 - val_loss: 1.1462\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1461\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9877 - val_loss: 1.1462\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.0493\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.9891 - val_loss: 1.1465\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 1.1467\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 1.1467\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 1.1468\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9890 - val_loss: 1.1468\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1468\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1469\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1468\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1469\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9890 - val_loss: 1.1469\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 1.1470\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 1.1470\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 1.1470\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1469\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 1.1470\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1469\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9891 - val_loss: 1.1470\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 1.1470\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9891 - val_loss: 1.1470\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.0445\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 1.1465\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9908 - val_loss: 1.1465\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 1.1465\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1464\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 1.1465\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 1.0367\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.0229 - val_loss: 1.1463\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1462\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1461\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1461\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1461\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1459\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1461\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1459\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1459\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1459\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.0229 - val_loss: 1.1459\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1460\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0229 - val_loss: 1.1459\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.9091\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.4303 - val_loss: 0.2982\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.2074 - val_loss: 0.2183\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1657 - val_loss: 0.1842\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1423 - val_loss: 0.1656\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1262 - val_loss: 0.1447\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1147 - val_loss: 0.1328\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.1066 - val_loss: 0.1253\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0995 - val_loss: 0.1182\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0946 - val_loss: 0.1107\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0892 - val_loss: 0.1052\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0856 - val_loss: 0.1023\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0830 - val_loss: 0.0993\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0793 - val_loss: 0.0949\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0776 - val_loss: 0.0883\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0751 - val_loss: 0.0880\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0735 - val_loss: 0.0821\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0718 - val_loss: 0.0811\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0704 - val_loss: 0.0776\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0689 - val_loss: 0.0838\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0681 - val_loss: 0.0756\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0666 - val_loss: 0.0761\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0662 - val_loss: 0.0741\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0653 - val_loss: 0.0724\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0653 - val_loss: 0.0731\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0644 - val_loss: 0.0703\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0635 - val_loss: 0.0723\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0624 - val_loss: 0.0690\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0628 - val_loss: 0.0684\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0624 - val_loss: 0.0690\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0621 - val_loss: 0.0714\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0617 - val_loss: 0.0683\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0616 - val_loss: 0.0677\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0612 - val_loss: 0.0670\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0603 - val_loss: 0.0686\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0603 - val_loss: 0.0653\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0599 - val_loss: 0.0663\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0596 - val_loss: 0.0629\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0689\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0588 - val_loss: 0.0652\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0579 - val_loss: 0.0642\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0582 - val_loss: 0.0664\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0575 - val_loss: 0.0649\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0576 - val_loss: 0.0652\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0571 - val_loss: 0.0641\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0567 - val_loss: 0.0647\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0573 - val_loss: 0.0610\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0558 - val_loss: 0.0642\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0564 - val_loss: 0.0602\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0559 - val_loss: 0.0652\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0558 - val_loss: 0.0611\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0561 - val_loss: 0.0618\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0551 - val_loss: 0.0600\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0553 - val_loss: 0.0613\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0558 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0549 - val_loss: 0.0617\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0543 - val_loss: 0.0577\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0549 - val_loss: 0.0587\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0544 - val_loss: 0.0587\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0539 - val_loss: 0.0621\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0550 - val_loss: 0.0578\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0532 - val_loss: 0.0615\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0530 - val_loss: 0.0588\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0538 - val_loss: 0.0579\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0536 - val_loss: 0.0589\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0531 - val_loss: 0.0585\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0529 - val_loss: 0.0581\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0527 - val_loss: 0.0595\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0538 - val_loss: 0.0571\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0531 - val_loss: 0.0578\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0525 - val_loss: 0.0568\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0522 - val_loss: 0.0563\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0521 - val_loss: 0.0591\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0523 - val_loss: 0.0562\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0516 - val_loss: 0.0579\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0519 - val_loss: 0.0582\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0510 - val_loss: 0.0573\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0506 - val_loss: 0.0617\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0513 - val_loss: 0.0577\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0495 - val_loss: 0.0631\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0511 - val_loss: 0.0561\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0505 - val_loss: 0.0543\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0507 - val_loss: 0.0583\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0500 - val_loss: 0.0551\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0504 - val_loss: 0.0571\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0500 - val_loss: 0.0551\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0504 - val_loss: 0.0550\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0500 - val_loss: 0.0588\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0495 - val_loss: 0.0568\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0502 - val_loss: 0.0552\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0501 - val_loss: 0.0540\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0497 - val_loss: 0.0557\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0497 - val_loss: 0.0613\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0501 - val_loss: 0.0546\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0495 - val_loss: 0.0546\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0491 - val_loss: 0.0548\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0488 - val_loss: 0.0532\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0487 - val_loss: 0.0536\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0487 - val_loss: 0.0573\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0495 - val_loss: 0.0541\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0488 - val_loss: 0.0530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f50617cb1d0>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'activation': ['relu', 'elu'],\n",
              "                                        'init': ['he_normal', 'random_normal',\n",
              "                                                 'glorot_normal'],\n",
              "                                        'learning_rate': [0.01, 0.001, 0.002],\n",
              "                                        'n_hidden': [5, 6, 7, 8],\n",
              "                                        'n_neurons': [20, 21, 22, 23, 24, 25,\n",
              "                                                      26, 27, 28, 29, 30, 31,\n",
              "                                                      32, 33, 34, 35, 36, 37,\n",
              "                                                      38, 39, 40, 41, 42, 43,\n",
              "                                                      44, 45, 46, 47, 48, 49, ...]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 74, 'n_hidden': 8, 'learning_rate': 0.002, 'init': 'glorot_normal', 'activation': 'elu'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n1gpd2IBNI3"
      },
      "source": [
        "Plot Loss vs Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wynsPAPWBMWv",
        "outputId": "7b644d09-c53f-456d-9740-bff35f59c886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "history = rnd_search_cv.best_estimator_.model.history\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5055e9fc88>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f506177fcf8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'model loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5055f3c7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt7kkW5MbYco"
      },
      "source": [
        "**Accuracy & Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiCp4tBZtu20"
      },
      "source": [
        "Train Set Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtQdoiKQbXuO",
        "outputId": "3ce1f797-714b-4adb-8edb-f1f27fb647a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "source": [
        "Y_train_pred_scaled = rnd_search_cv.predict(X_train_scaled)\n",
        "Y_train_pred = scalerY.inverse_transform(Y_train_pred_scaled)\n",
        "\n",
        "results = X_train.copy()\n",
        "results[\"predicted\"] = Y_train_pred\n",
        "results[\"actual\"] = Y_train\n",
        "results = results[['predicted', 'actual']]\n",
        "results['predicted'] = results['predicted'].round(0)\n",
        "results\n",
        "\n",
        "# reset the index of DataFrame and use the default indexing (0 1 2 3...N-1)\n",
        "results = pd.DataFrame.reset_index(results, drop=True)\n",
        "\n",
        "# visualize predicted vs actual in train set\n",
        "plt.plot(results['predicted'].head(100), label='predicted')\n",
        "plt.plot(results['actual'].head(100), label='actual')\n",
        "plt.xlabel('index in train set')\n",
        "plt.ylabel('price')\n",
        "plt.title('Predicted vs Actual in Train set')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2390</th>\n",
              "      <td>20007.0</td>\n",
              "      <td>18990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7219</th>\n",
              "      <td>13785.0</td>\n",
              "      <td>12995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>20245.0</td>\n",
              "      <td>21888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3920</th>\n",
              "      <td>32646.0</td>\n",
              "      <td>27990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4539</th>\n",
              "      <td>11771.0</td>\n",
              "      <td>14700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4305</th>\n",
              "      <td>29251.0</td>\n",
              "      <td>31000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>40864.0</td>\n",
              "      <td>32996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1572</th>\n",
              "      <td>42469.0</td>\n",
              "      <td>43490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10245</th>\n",
              "      <td>14975.0</td>\n",
              "      <td>17000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7982</th>\n",
              "      <td>17811.0</td>\n",
              "      <td>16999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6400 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted  actual\n",
              "2390     20007.0   18990\n",
              "7219     13785.0   12995\n",
              "873      20245.0   21888\n",
              "3920     32646.0   27990\n",
              "4539     11771.0   14700\n",
              "...          ...     ...\n",
              "4305     29251.0   31000\n",
              "1023     40864.0   32996\n",
              "1572     42469.0   43490\n",
              "10245    14975.0   17000\n",
              "7982     17811.0   16999\n",
              "\n",
              "[6400 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f505ca02dd8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f505ca02fd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'index in train set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'price')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Predicted vs Actual in Train set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5058abb4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iiW7B7OEhsQ"
      },
      "source": [
        "Test Set Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asBjf_gAtqcJ",
        "outputId": "17983c7d-523f-4f10-cef8-a5a08e8aeb0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "source": [
        "Y_test_pred_scaled = rnd_search_cv.predict(X_test_scaled)\n",
        "Y_test_pred = scalerY.inverse_transform(Y_test_pred_scaled)\n",
        "\n",
        "# copy the DataFrame indexes\n",
        "test_results = X_test.copy()\n",
        "test_results[\"predicted\"] = Y_test_pred\n",
        "test_results[\"actual\"] = Y_test\n",
        "test_results = test_results[['predicted', 'actual']]\n",
        "test_results['predicted'] = test_results['predicted'].round(0)\n",
        "test_results\n",
        "\n",
        "# reset the index of DataFrame and use the default indexing (0 1 2 3...N-1)\n",
        "test_results = pd.DataFrame.reset_index(test_results, drop=True)\n",
        "\n",
        "# visualize predicted vs actual in test set\n",
        "plt.plot(test_results['predicted'].head(100), label='predicted')\n",
        "plt.plot(test_results['actual'].head(100), label='actual')\n",
        "plt.xlabel('index in test set')\n",
        "plt.ylabel('price')\n",
        "plt.title('Predicted vs Actual in test set')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10442</th>\n",
              "      <td>10130.0</td>\n",
              "      <td>9990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2907</th>\n",
              "      <td>20514.0</td>\n",
              "      <td>22382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7388</th>\n",
              "      <td>30971.0</td>\n",
              "      <td>28990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>25626.0</td>\n",
              "      <td>30777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7890</th>\n",
              "      <td>15090.0</td>\n",
              "      <td>14950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8606</th>\n",
              "      <td>31040.0</td>\n",
              "      <td>31450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8977</th>\n",
              "      <td>14732.0</td>\n",
              "      <td>12900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3673</th>\n",
              "      <td>15900.0</td>\n",
              "      <td>16750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>20748.0</td>\n",
              "      <td>21996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6867</th>\n",
              "      <td>11743.0</td>\n",
              "      <td>9547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2134 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predicted  actual\n",
              "10442    10130.0    9990\n",
              "2907     20514.0   22382\n",
              "7388     30971.0   28990\n",
              "3016     25626.0   30777\n",
              "7890     15090.0   14950\n",
              "...          ...     ...\n",
              "8606     31040.0   31450\n",
              "8977     14732.0   12900\n",
              "3673     15900.0   16750\n",
              "1034     20748.0   21996\n",
              "6867     11743.0    9547\n",
              "\n",
              "[2134 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f505ce85e80>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f506ddfcef0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'index in test set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'price')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Predicted vs Actual in test set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f505ce85ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naLNVRw4zE7O"
      },
      "source": [
        "Define a DataFrame object to store evaluation performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GzcSKWRzJDM"
      },
      "source": [
        "model_performance = pd.DataFrame(columns=['Model', 'Train MAE', 'Train RMSE', \n",
        "                      'Test MAE', 'Test RMSE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzjdXFDY0Bsp"
      },
      "source": [
        "Train Set Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kSnaBRW0Don"
      },
      "source": [
        "Train_MAE = mean_absolute_error(Y_train, Y_train_pred).round(0)\n",
        "Train_RMSE = np.sqrt(mean_squared_error(Y_train, Y_train_pred)).round(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBxpObiu0MJH"
      },
      "source": [
        "Test Set Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW9ap8tz0Nog"
      },
      "source": [
        "Test_MAE = mean_absolute_error(Y_test, Y_test_pred).round(0)\n",
        "Test_RMSE = np.sqrt(mean_squared_error(Y_test, Y_test_pred)).round(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY9Rkuc0aX1t"
      },
      "source": [
        "Model Performance Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylrr8osY0wwA",
        "outputId": "1487c57f-f7e8-4a62-9c6a-2b4b0c86bed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "model_performance = model_performance.append({'Model': rnd_search_cv.best_params_,\n",
        "                        'Train MAE': Train_MAE, \n",
        "                        'Train RMSE': Train_RMSE,\n",
        "                        'Test MAE': Test_MAE, \n",
        "                        'Test RMSE': Test_RMSE},\n",
        "                        ignore_index=True)\n",
        "model_performance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Train MAE</th>\n",
              "      <th>Train RMSE</th>\n",
              "      <th>Test MAE</th>\n",
              "      <th>Test RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'n_neurons': 74, 'n_hidden': 8, 'learning_rat...</td>\n",
              "      <td>1715.0</td>\n",
              "      <td>2494.0</td>\n",
              "      <td>1843.0</td>\n",
              "      <td>2701.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Model  ...  Test RMSE\n",
              "0  {'n_neurons': 74, 'n_hidden': 8, 'learning_rat...  ...     2701.0\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}